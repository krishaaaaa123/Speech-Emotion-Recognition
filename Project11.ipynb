{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7VaZbeGNNJCnph0kgMTwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishaaaaa123/Speech-Emotion-Recognition/blob/main/Project11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EyuQr-Je9LYZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = []\n",
        "labels = []\n",
        "for dirname, _, filenames in os.walk('D:\\krishshshsh\\TESS Toronto emotional speech set data'):\n",
        "   for filename in filenames:\n",
        "     paths.append(os.path.join(dirname, filename))\n",
        "     label = filename.split('_')[-1]\n",
        "     label = label.split('.')[0]\n",
        "     labels.append(label.lower())\n",
        "\n",
        "print('Dataset is loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boDdsOIr9wF2",
        "outputId": "210f6c15-612e-494d-fbd5-8d9eada36a78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths[:5]"
      ],
      "metadata": {
        "id": "I1-YQa65Achb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:5]"
      ],
      "metadata": {
        "id": "d1AmOFk0Af4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataframe\n",
        "df = pd.DataFrame()\n",
        "df['speech'] = paths\n",
        "df['label'] = labels\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1xP50MxoAiXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "AHsxlk9GA-8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploratory Data Analysis\n",
        "\n",
        "sns.countplot(df['label'])"
      ],
      "metadata": {
        "id": "XgN6LGibW53C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def waveplot(data,sr, emotion):\n",
        "  plt.figure(figsize=(10,4))\n",
        "  plt.title(emotion, size=20)\n",
        "\n",
        "  librosa.display.waveplot(data, sr=sr)\n",
        "  plt.show()\n",
        "\n",
        "def spectogram(data, sr, emotion):\n",
        "  x = librosa.stft(data)\n",
        "  xdb = librosa.amplitude_to_db(abs(x))\n",
        "  plt.figure(figsize=(10,4))\n",
        "  plt.title(emotion, size=20)\n",
        "  librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "  plt.colorbar()\n",
        ""
      ],
      "metadata": {
        "id": "q5IICqNoBTY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'fear'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "mNyzp6H3Cm8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'angry'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "ucSQhoOzDPUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'disgust'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "XBgrcwhFELkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'neutral'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "SPvzVqMcENTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'sad'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "6jm3XGbuEdFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'ps'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "dZ7nJAkrEkz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = 'happy'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "waveplot(data, sampling_rate, emotion)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "id": "f3fcz4HhEmti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(filename):\n",
        "  y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
        "  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "  return mfcc"
      ],
      "metadata": {
        "id": "q322dXEQE-8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_mfcc(df['speech'][0])"
      ],
      "metadata": {
        "id": "MD1gAcv5Ftdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"
      ],
      "metadata": {
        "id": "sp8-2tBwFy10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mfcc"
      ],
      "metadata": {
        "id": "fqtCK13fGFfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [x for x in X_mfcc]\n",
        "X = np.array(X)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "NmN7Pcb9HfTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input split\n",
        "X = np.expand_dims(X, -1)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "EorCu7zQGHc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "y = enc.fit_transform(df[['label']])"
      ],
      "metadata": {
        "id": "W7r1g8iPG3wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.toarray()"
      ],
      "metadata": {
        "id": "R-w2EREuIhlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "7OzT_STWIlC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(123, return_sequences=False, input_shape=(40,1)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0,2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0,2),\n",
        "    Dense(7, activation='softmax'),\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bammXNizI_qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "history = model.fit(X, y, validation_split=0.2, epochs=100, batch_size=512, shuffle=True)"
      ],
      "metadata": {
        "id": "laM4BtGHNBF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the Results\n",
        "epochs = list(range(100))\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, label = 'train accuracy')\n",
        "plt.plot(epochs, val_acc, label = 'val accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NK0kXQfyObqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, loss, label = 'train loss')\n",
        "plt.plot(epochs, val_loss, label = 'val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NpOA4ADPPXXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}